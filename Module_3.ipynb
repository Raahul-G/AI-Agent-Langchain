{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfd1903b",
   "metadata": {},
   "source": [
    "# Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65d91bd",
   "metadata": {},
   "source": [
    "Goals\n",
    "\n",
    "This module will dive into `human-in-the-loop`, which builds on memory and allows users to interact directly with graphs in various ways. \n",
    "\n",
    "To set the stage for `human-in-the-loop`, we'll first dive into streaming, which provides several ways to visualize graph output (e.g., node state or chat model tokens) over the course of execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eb665f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "model = ChatOpenAI(model='gpt-4.1-nano', temperature=0)\n",
    "\n",
    "class State(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "def call_mode(state:State, config: RunnableConfig):\n",
    "\n",
    "    summary = state.get(\"summary\",\"\")\n",
    "\n",
    "    if summary:\n",
    "\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    \n",
    "    else:\n",
    "\n",
    "        messages = state['messages']\n",
    "\n",
    "    response = model.invoke(messages, config)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def summarize_conversation(state:State):\n",
    "\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    if summary:\n",
    "\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary} \\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "def should_conitinue(state:State):\n",
    "\n",
    "    messages = state['messages']\n",
    "\n",
    "    if len(messages) >6:\n",
    "        return \"summarize_conversation\"\n",
    "\n",
    "    return END\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"conversation\", call_mode)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_conitinue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8f1754",
   "metadata": {},
   "source": [
    "## Streaming full state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7e8fcc",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "[stream our graph state](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "`.stream` and `.astream` are sync and async methods for streaming back results. \n",
    " \n",
    "LangGraph supports a few [different streaming modes](https://langchain-ai.github.io/langgraph/how-tos/stream-values/) for [graph state](https://langchain-ai.github.io/langgraph/how-tos/stream-values/):\n",
    " \n",
    "* `values`: This streams the full state of the graph after each node is called.\n",
    "* `updates`: This streams updates to the state of the graph after each node is called.\n",
    "\n",
    "![values_vs_updates.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf892d24625a201744e5_streaming1.png)\n",
    "\n",
    "Let's look at `stream_mode=\"updates\"`.\n",
    "\n",
    "Because we stream with `updates`, we only see updates to the state after node in the graph is run.\n",
    "\n",
    "Each `chunk` is a dict with `node_name` as the key and the updated state as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcbca351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversation': {'messages': AIMessage(content='Hello, Raahul! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 13, 'total_tokens': 27, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_eede8f0d45', 'id': 'chatcmpl-BXTshB5HKm72eKTyHTjAbPwJPErCJ', 'finish_reason': 'stop', 'logprobs': None}, id='run-793bb093-5ad1-4121-aaee-26c6be6f8faf-0', usage_metadata={'input_tokens': 13, 'output_tokens': 14, 'total_tokens': 27, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}}\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {'thread_id':\"1\"}}\n",
    "\n",
    "for chunk in graph.stream({'messages': [HumanMessage(content=\"hi! I'm Raahul\")]}, config, stream_mode=\"updates\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e559f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi, Raahul! Nice to meet you. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Raahul\")]}, config, stream_mode=\"updates\"):\n",
    "    chunk['conversation'][\"messages\"].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b856040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Leo Das\n",
      "------------------------------------------------------------------------------------------\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Leo Das\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Leo! Nice to meet you. How can I assist you today?\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hi! I'm Leo Das\")\n",
    "for event in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    for m in event['messages']:\n",
    "        m.pretty_print()\n",
    "    print(\"---\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6818142",
   "metadata": {},
   "source": [
    "## Streaming tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a121d70e",
   "metadata": {},
   "source": [
    "We often want to stream more than graph state.\n",
    "\n",
    "In particular, with chat model calls it is common to stream the tokens as they are generated.\n",
    "\n",
    "We can do this [using the `.astream_events` method](https://langchain-ai.github.io/langgraph/how-tos/streaming-from-final-node/#stream-outputs-from-the-final-node), which streams back events as they happen inside nodes!\n",
    "\n",
    "Each event is a dict with a few keys:\n",
    " \n",
    "* `event`: This is the type of event that is being emitted. \n",
    "* `name`: This is the name of event.\n",
    "* `data`: This is the data associated with the event.\n",
    "* `metadata`: Contains`langgraph_node`, the node emitting the event.\n",
    "\n",
    "Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a20bbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: . Type: on_chain_start. Name: {event['name]}\n",
      "Node: conversation. Type: on_chain_start. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_start. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chat_model_end. Name: {event['name]}\n",
      "Node: conversation. Type: on_chain_start. Name: {event['name]}\n",
      "Node: conversation. Type: on_chain_end. Name: {event['name]}\n",
      "Node: conversation. Type: on_chain_stream. Name: {event['name]}\n",
      "Node: conversation. Type: on_chain_end. Name: {event['name]}\n",
      "Node: . Type: on_chain_stream. Name: {event['name]}\n",
      "Node: . Type: on_chain_end. Name: {event['name]}\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\":{\"thread_id\":\"3\"}}\n",
    "\n",
    "input_message = HumanMessage(content=f\"Tell me about RCB\")\n",
    "async for event in graph.astream_events({\"messages\":[input_message]}, config, version=\"v2\"):\n",
    "    print(f\"Node: {event['metadata'].get('langgraph_node', '')}. Type: {event['event']}. Name: {{event['name]}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d1e50f",
   "metadata": {},
   "source": [
    "The central point is that tokens from chat models within your graph have the `on_chat_model_stream` type.\n",
    "\n",
    "We can use `event['metadata']['langgraph_node']` to select the node to stream from.\n",
    "\n",
    "And we can use `event['data']` to get the actual data for each event, which in this case is an `AIMessageChunk`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "610a8c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='Certainly', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='!', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' R', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='CB', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' or', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Royal', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Chall', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='engers', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Bangalore', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' professional', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Twenty', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='20', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' cricket', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' based', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Bangalore', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Karnataka', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' India', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' They', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' one', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' franchises', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' that', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' compete', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Indian', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Premier', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' League', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='IPL', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='),', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' which', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' one', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' most', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' popular', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' competitive', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' T', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='20', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' cricket', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' leagues', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' world', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='Key', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Facts', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' about', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' R', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='CB', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='**\\n\\n', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='Founded', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='200', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='8', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' inaugural', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' season', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' IPL', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='Ownership', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' owned', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' by', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' United', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Spirits', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' subsidiary', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Di', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='age', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='o', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='Team', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Colors', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Red', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' black', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='Home', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Ground', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' M', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Ch', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='inn', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='as', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='w', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='amy', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Stadium', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Bangalore', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='Team', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Nick', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='name', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=':**', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Chall', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='engers', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='Performance', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Highlights', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='**\\n\\n', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' R', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='CB', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' known', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' its', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' explosive', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' batting', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' lineup', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' has', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' featured', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' some', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' biggest', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' names', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' cricket', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Despite', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' popularity', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' star', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='-st', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='udd', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='ed', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' squads', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' R', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='CB', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' has', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' yet', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' win', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' an', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' IPL', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' title', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' though', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' they', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' reached', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' finals', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' three', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' times', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='200', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='201', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='1', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='201', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='6', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=').\\n', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' They', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' passionate', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' fan', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' base', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' considered', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' one', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' most', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' popular', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' teams', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' league', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='Not', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='able', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Players', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='**\\n\\n', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Vir', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='at', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Koh', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='li', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='former', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' captain', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' one', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' leading', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' run', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='-s', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='cor', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' IPL', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' history', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=')\\n', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' AB', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' de', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Vill', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='iers', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Chris', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Gay', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='le', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Y', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='uz', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='v', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='endra', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Ch', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='ahal', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Glenn', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Maxwell', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='\\n\\n', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='Team', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Identity', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='**\\n\\n', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='RC', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='B', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' often', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' celebrated', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' aggressive', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' batting', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' style', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' entertaining', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' cricket', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' Their', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' motto', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' emphasizes', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' entertainment', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' high', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='-sc', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='oring', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' matches', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' making', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' them', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' fan', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' favorite', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' despite', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' lack', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' an', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' IPL', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' championship', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' victory', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='If', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=\" you'd\", additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' like', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' more', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' specific', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' information', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' or', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' updates', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' feel', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' free', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content=' ask', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='!', additional_kwargs={}, response_metadata={}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n",
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_8fd43718b3'}, id='run-2aa76711-f591-4c5d-a2e6-2e73f4673e3e')}\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\":{\"thread_id\":\"4\"}}\n",
    "node_to_stream = 'conversation'\n",
    "\n",
    "input_message = HumanMessage(content=f\"Tell me about RCB\")\n",
    "async for event in graph.astream_events({\"messages\":[input_message]}, config, version=\"v2\"):\n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node', '') == node_to_stream:\n",
    "        print(event['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27ec18a",
   "metadata": {},
   "source": [
    "As you see above, just use the `chunk` key to get the `AIMessageChunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36615970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Certainly|!| R|CB|,| or| Royal| Chall|engers| Bangalore|,| is| a| professional| Twenty|20| cricket| team| based| in| Bangalore|,| Karnataka|,| India|.| They| compete| in| the| Indian| Premier| League| (|IPL|),| which| is| one| of| the| most| popular| and| competitive| T|20| cricket| leagues| in| the| world|.\n",
      "\n",
      "|**|Key| Facts| about| R|CB|:|**\n",
      "\n",
      "|-| **|Founded|:**| |200|8|,| the| inaugural| season| of| the| IPL|.\n",
      "|-| **|Ownership|:**| The| team| is| owned| by| United| Spirits|,| a| subsidiary| of| Di|age|o|.\n",
      "|-| **|Team| Colors|:**| Red| and| black|.\n",
      "|-| **|Home| Ground|:**| M|.| Ch|inn|as|w|amy| Stadium| in| Bangalore|,| which| has| a| seating| capacity| of| around| |40|,|000| spectators|.\n",
      "|-| **|Team| Nick|name|:**| The| Chall|engers|.\n",
      "\n",
      "|**|Performance| Highlights|:|**\n",
      "\n",
      "|-| R|CB| is| known| for| its| explosive| batting| lineup| and| has| featured| some| of| the| biggest| names| in| cricket|.\n",
      "|-| Despite| having| a| strong| squad| over| the| years|,| R|CB| has| yet| to| win| an| IPL| title|,| but| they| have| been| runners|-up| three| times| (|200|9|,| |201|1|,| and| |201|6|).\n",
      "|-| The| team| has| produced| several| notable| players|,| including| Vir|at| Koh|li| (|who| has| been| the| captain| and| one| of| the| leading| run|-s|cor|ers| in| IPL| history|),| AB| de| Vill|iers|,| Chris| Gay|le|,| and| many| others|.\n",
      "\n",
      "|**|Not|able| Players|:|**\n",
      "\n",
      "|-| **|Vir|at| Koh|li|:**| One| of| the| most| prolific| bats|men| in| cricket| history|.\n",
      "|-| **|AB| de| Vill|iers|:**| Ren|owned| for| his| innovative| batting| and| versatility|.\n",
      "|-| **|Chris| Gay|le|:**| Known| for| his| powerful| hitting| and| record|-breaking| performances|.\n",
      "\n",
      "|**|Fan| Base|:|**\n",
      "\n",
      "|RC|B| has| a| passionate| and| large| fan| following|,| both| in| India| and| internationally|,| often| celebrated| for| their| entertaining| style| of| play| and| star|-st|udd|ed| line|ups|.\n",
      "\n",
      "|**|Recent| Performance|:|**\n",
      "\n",
      "|As| of| |202|3|,| R|CB| continues| to| be| a| competitive| team|,| aiming| to| secure| their| first| IPL| championship|.| They| are| known| for| their| aggressive| batting| approach| and| talented| squad|.\n",
      "\n",
      "|If| you'd| like| more| specific| details| or| updates| on| recent| seasons|,| feel| free| to| ask|!||"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about RCB\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        data = event[\"data\"]\n",
    "        print(data[\"chunk\"].content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46295e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "URL = \"http://127.0.0.1:2024\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "assistanst = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13b3c030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamPart(event='metadata', data={'run_id': '1f031991-847a-6728-af53-70be359c8024', 'attempt': 1})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 5', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '69320573-0860-4b94-8f9c-0af39c3ebf97', 'example': False}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 5', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '69320573-0860-4b94-8f9c-0af39c3ebf97', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'id': 'call_t4MeE7CCsT4FfIGNsmoEsfjx', 'function': {'arguments': '{\"a\":2,\"b\":5}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 18, 'prompt_tokens': 134, 'total_tokens': 152, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_55d88aaf2f', 'id': 'chatcmpl-BXTt02NE8BIsEDSvUB4Q92yM9qwim', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run-175276b4-6ef4-483c-a9f7-c75db96948a2-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 5}, 'id': 'call_t4MeE7CCsT4FfIGNsmoEsfjx', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 134, 'output_tokens': 18, 'total_tokens': 152, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 5', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '69320573-0860-4b94-8f9c-0af39c3ebf97', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'id': 'call_t4MeE7CCsT4FfIGNsmoEsfjx', 'function': {'arguments': '{\"a\":2,\"b\":5}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 18, 'prompt_tokens': 134, 'total_tokens': 152, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_55d88aaf2f', 'id': 'chatcmpl-BXTt02NE8BIsEDSvUB4Q92yM9qwim', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run-175276b4-6ef4-483c-a9f7-c75db96948a2-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 5}, 'id': 'call_t4MeE7CCsT4FfIGNsmoEsfjx', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 134, 'output_tokens': 18, 'total_tokens': 152, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}, {'content': '10', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': 'df8fd66d-fbab-4759-b86e-0a8920dcf813', 'tool_call_id': 'call_t4MeE7CCsT4FfIGNsmoEsfjx', 'artifact': None, 'status': 'success'}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 5', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '69320573-0860-4b94-8f9c-0af39c3ebf97', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'id': 'call_t4MeE7CCsT4FfIGNsmoEsfjx', 'function': {'arguments': '{\"a\":2,\"b\":5}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 18, 'prompt_tokens': 134, 'total_tokens': 152, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_55d88aaf2f', 'id': 'chatcmpl-BXTt02NE8BIsEDSvUB4Q92yM9qwim', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run-175276b4-6ef4-483c-a9f7-c75db96948a2-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 5}, 'id': 'call_t4MeE7CCsT4FfIGNsmoEsfjx', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 134, 'output_tokens': 18, 'total_tokens': 152, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}, {'content': '10', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': 'df8fd66d-fbab-4759-b86e-0a8920dcf813', 'tool_call_id': 'call_t4MeE7CCsT4FfIGNsmoEsfjx', 'artifact': None, 'status': 'success'}, {'content': 'The result of multiplying 2 and 5 is 10.', 'additional_kwargs': {'refusal': None}, 'response_metadata': {'token_usage': {'completion_tokens': 15, 'prompt_tokens': 159, 'total_tokens': 174, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_55d88aaf2f', 'id': 'chatcmpl-BXTt1399TIGfPVyk817RuhpDDN941', 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run-43ef83d7-9ff1-44a0-9365-3da1597f2541-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 159, 'output_tokens': 15, 'total_tokens': 174, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}}]})\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 5\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"],\n",
    "                                      assistant_id='agent',\n",
    "                                      input={\"messages\": [input_message]},\n",
    "                                      stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1325ef45",
   "metadata": {},
   "source": [
    "The streamed objects have: \n",
    "\n",
    "* `event`: Type\n",
    "* `data`: State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ae15059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "content='Multiply 2 and 5' additional_kwargs={} response_metadata={} id='42d9c538-5ac4-4049-ae41-41f0b2cc3950'\n",
      "==================================================\n",
      "content='' additional_kwargs={'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 134, 'output_tokens': 17, 'total_tokens': 151, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}, 'tool_calls': [{'id': 'call_gwHTlDZx6sZREPZg4JWt7cmt', 'function': {'arguments': '{\"a\":2,\"b\":5}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 134, 'total_tokens': 151, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_55d88aaf2f', 'id': 'chatcmpl-BXTt3RH5ARgpt3ElgYohTkH1J6mSx', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-ce0c1d02-e56f-457e-98d7-ce0e1abe446c-0' tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 5}, 'id': 'call_gwHTlDZx6sZREPZg4JWt7cmt', 'type': 'tool_call'}]\n",
      "==================================================\n",
      "content='10' name='multiply' id='9f922e77-dee7-404d-96b0-83d92bd9ac6d' tool_call_id='call_gwHTlDZx6sZREPZg4JWt7cmt'\n",
      "==================================================\n",
      "content='The result of multiplying 2 and 5 is 10.' additional_kwargs={'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 159, 'output_tokens': 14, 'total_tokens': 173, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}, 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 159, 'total_tokens': 173, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_55d88aaf2f', 'id': 'chatcmpl-BXTt3QrJynDO5F9BO9Opjz9pyTvs3', 'finish_reason': 'stop', 'logprobs': None} id='run-055a8c06-f5bb-40de-983c-8adf7b3eb0d8-0'\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "\n",
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 5\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"agent\", input={\"messages\":[input_message]}, stream_mode=\"values\"):\n",
    "    messages = event.data.get('messages', None)\n",
    "    if messages:\n",
    "        print(convert_to_messages(messages)[-1])\n",
    "    print('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e82ee1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/metadata\n",
      "messages/complete\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"messages\"):\n",
    "    print(event.event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54dcce44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'run_id': '1f031991-c25d-6891-beaf-4b297ab835f8', 'attempt': 1}\n",
      "{'run-e8e90b7a-4f00-4a56-856b-984a6f7d39e7': {'metadata': {'created_by': 'system', 'graph_id': 'agent', 'assistant_id': 'fe096781-5601-53d2-b2f6-0d3403f7e9ca', 'run_attempt': 1, 'langgraph_version': '0.3.34', 'langgraph_plan': 'developer', 'langgraph_host': 'self-hosted', 'langgraph_api_url': 'http://127.0.0.1:2024', 'user-agent': 'langgraph-sdk-py/0.1.63', 'langgraph_auth_user_id': '', 'run_id': '1f031991-c25d-6891-beaf-4b297ab835f8', 'thread_id': '39c360bd-8c26-4e1b-9a39-2459b0b8a3bb', 'user_id': '', 'langgraph_step': 1, 'langgraph_node': 'assistant', 'langgraph_triggers': ['branch:to:assistant'], 'langgraph_path': ['__pregel_pull', 'assistant'], 'langgraph_checkpoint_ns': 'assistant:a8034d6c-5a7f-baf3-839b-c8d48902bc1d', 'checkpoint_ns': 'assistant:a8034d6c-5a7f-baf3-839b-c8d48902bc1d', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': None}}}\n",
      "[{'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_gNiwjv7HDSRuvJpw7NsRoyu0', 'function': {'arguments': '', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-e8e90b7a-4f00-4a56-856b-984a6f7d39e7', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {}, 'id': 'call_gNiwjv7HDSRuvJpw7NsRoyu0', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "[{'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_gNiwjv7HDSRuvJpw7NsRoyu0', 'function': {'arguments': '{\"', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-e8e90b7a-4f00-4a56-856b-984a6f7d39e7', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {}, 'id': 'call_gNiwjv7HDSRuvJpw7NsRoyu0', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "[{'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_gNiwjv7HDSRuvJpw7NsRoyu0', 'function': {'arguments': '{\"a', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-e8e90b7a-4f00-4a56-856b-984a6f7d39e7', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {}, 'id': 'call_gNiwjv7HDSRuvJpw7NsRoyu0', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "[{'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_gNiwjv7HDSRuvJpw7NsRoyu0', 'function': {'arguments': '{\"a\":', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-e8e90b7a-4f00-4a56-856b-984a6f7d39e7', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {}, 'id': 'call_gNiwjv7HDSRuvJpw7NsRoyu0', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "[{'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_gNiwjv7HDSRuvJpw7NsRoyu0', 'function': {'arguments': '{\"a\":2', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-e8e90b7a-4f00-4a56-856b-984a6f7d39e7', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2}, 'id': 'call_gNiwjv7HDSRuvJpw7NsRoyu0', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "[{'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_gNiwjv7HDSRuvJpw7NsRoyu0', 'function': {'arguments': '{\"a\":2,\"', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-e8e90b7a-4f00-4a56-856b-984a6f7d39e7', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2}, 'id': 'call_gNiwjv7HDSRuvJpw7NsRoyu0', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "[{'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_gNiwjv7HDSRuvJpw7NsRoyu0', 'function': {'arguments': '{\"a\":2,\"b', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-e8e90b7a-4f00-4a56-856b-984a6f7d39e7', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2}, 'id': 'call_gNiwjv7HDSRuvJpw7NsRoyu0', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "[{'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_gNiwjv7HDSRuvJpw7NsRoyu0', 'function': {'arguments': '{\"a\":2,\"b\":', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-e8e90b7a-4f00-4a56-856b-984a6f7d39e7', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2}, 'id': 'call_gNiwjv7HDSRuvJpw7NsRoyu0', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "[{'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_gNiwjv7HDSRuvJpw7NsRoyu0', 'function': {'arguments': '{\"a\":2,\"b\":3', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-e8e90b7a-4f00-4a56-856b-984a6f7d39e7', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_gNiwjv7HDSRuvJpw7NsRoyu0', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "[{'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_gNiwjv7HDSRuvJpw7NsRoyu0', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-e8e90b7a-4f00-4a56-856b-984a6f7d39e7', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_gNiwjv7HDSRuvJpw7NsRoyu0', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "[{'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_gNiwjv7HDSRuvJpw7NsRoyu0', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_55d88aaf2f'}, 'type': 'ai', 'name': None, 'id': 'run-e8e90b7a-4f00-4a56-856b-984a6f7d39e7', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_gNiwjv7HDSRuvJpw7NsRoyu0', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "{'a53f03f0-cd4b-41db-b4be-2d9472e774a8': {'metadata': {'created_by': 'system', 'graph_id': 'agent', 'assistant_id': 'fe096781-5601-53d2-b2f6-0d3403f7e9ca', 'run_attempt': 1, 'langgraph_version': '0.3.34', 'langgraph_plan': 'developer', 'langgraph_host': 'self-hosted', 'langgraph_api_url': 'http://127.0.0.1:2024', 'user-agent': 'langgraph-sdk-py/0.1.63', 'langgraph_auth_user_id': '', 'run_id': '1f031991-c25d-6891-beaf-4b297ab835f8', 'thread_id': '39c360bd-8c26-4e1b-9a39-2459b0b8a3bb', 'user_id': '', 'langgraph_step': 2, 'langgraph_node': 'tools', 'langgraph_triggers': ['branch:to:tools'], 'langgraph_path': ['__pregel_pull', 'tools'], 'langgraph_checkpoint_ns': 'tools:26584f25-2f15-1e20-0075-bb35ce472a15'}}}\n",
      "[{'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': 'a53f03f0-cd4b-41db-b4be-2d9472e774a8', 'tool_call_id': 'call_gNiwjv7HDSRuvJpw7NsRoyu0', 'artifact': None, 'status': 'success'}]\n",
      "{'run-675068d1-8019-4cbf-9f04-c82c27319082': {'metadata': {'created_by': 'system', 'graph_id': 'agent', 'assistant_id': 'fe096781-5601-53d2-b2f6-0d3403f7e9ca', 'run_attempt': 1, 'langgraph_version': '0.3.34', 'langgraph_plan': 'developer', 'langgraph_host': 'self-hosted', 'langgraph_api_url': 'http://127.0.0.1:2024', 'user-agent': 'langgraph-sdk-py/0.1.63', 'langgraph_auth_user_id': '', 'run_id': '1f031991-c25d-6891-beaf-4b297ab835f8', 'thread_id': '39c360bd-8c26-4e1b-9a39-2459b0b8a3bb', 'user_id': '', 'langgraph_step': 3, 'langgraph_node': 'assistant', 'langgraph_triggers': ['branch:to:assistant'], 'langgraph_path': ['__pregel_pull', 'assistant'], 'langgraph_checkpoint_ns': 'assistant:7c966edc-c39e-b222-6931-166ccad33c92', 'checkpoint_ns': 'assistant:7c966edc-c39e-b222-6931-166ccad33c92', 'ls_provider': 'openai', 'ls_model_name': 'gpt-4o', 'ls_model_type': 'chat', 'ls_temperature': None}}}\n",
      "[{'content': '', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-675068d1-8019-4cbf-9f04-c82c27319082', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "[{'content': 'The', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-675068d1-8019-4cbf-9f04-c82c27319082', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "[{'content': 'The result', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-675068d1-8019-4cbf-9f04-c82c27319082', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "[{'content': 'The result of', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-675068d1-8019-4cbf-9f04-c82c27319082', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "[{'content': 'The result of multiplying', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-675068d1-8019-4cbf-9f04-c82c27319082', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "[{'content': 'The result of multiplying ', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-675068d1-8019-4cbf-9f04-c82c27319082', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "[{'content': 'The result of multiplying 2', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-675068d1-8019-4cbf-9f04-c82c27319082', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "[{'content': 'The result of multiplying 2 and', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-675068d1-8019-4cbf-9f04-c82c27319082', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "[{'content': 'The result of multiplying 2 and ', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-675068d1-8019-4cbf-9f04-c82c27319082', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "[{'content': 'The result of multiplying 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-675068d1-8019-4cbf-9f04-c82c27319082', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "[{'content': 'The result of multiplying 2 and 3 is', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-675068d1-8019-4cbf-9f04-c82c27319082', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "[{'content': 'The result of multiplying 2 and 3 is ', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-675068d1-8019-4cbf-9f04-c82c27319082', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "[{'content': 'The result of multiplying 2 and 3 is 6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-675068d1-8019-4cbf-9f04-c82c27319082', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "[{'content': 'The result of multiplying 2 and 3 is 6.', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': 'run-675068d1-8019-4cbf-9f04-c82c27319082', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]\n",
      "[{'content': 'The result of multiplying 2 and 3 is 6.', 'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_55d88aaf2f'}, 'type': 'ai', 'name': None, 'id': 'run-675068d1-8019-4cbf-9f04-c82c27319082', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"messages\"):\n",
    "    print(event.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3bb8ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: Run ID - 1f031991-da08-662f-a2fe-a68a1b01b889\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_8yzEGWif48SGxemCDrl8acVZ, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_8yzEGWif48SGxemCDrl8acVZ, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_8yzEGWif48SGxemCDrl8acVZ, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_8yzEGWif48SGxemCDrl8acVZ, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_8yzEGWif48SGxemCDrl8acVZ, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_8yzEGWif48SGxemCDrl8acVZ, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_8yzEGWif48SGxemCDrl8acVZ, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_8yzEGWif48SGxemCDrl8acVZ, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_8yzEGWif48SGxemCDrl8acVZ, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_8yzEGWif48SGxemCDrl8acVZ, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_8yzEGWif48SGxemCDrl8acVZ, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "Response Metadata: Finish Reason - tool_calls\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "AI: The\n",
      "--------------------------------------------------\n",
      "AI: The result\n",
      "--------------------------------------------------\n",
      "AI: The result of\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "Response Metadata: Finish Reason - stop\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "\n",
    "def format_tool_calls(tool_calls):\n",
    "    \"\"\"\n",
    "    Format a list of tool calls into a readable string.\n",
    "\n",
    "    Args:\n",
    "        tool_calls (list): A list of dictionaries, each representing a tool call.\n",
    "            Each dictionary should have 'id', 'name', and 'args' keys.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string of tool calls, or \"No tool calls\" if the list is empty.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if tool_calls:\n",
    "        formatted_calls = []\n",
    "        for call in tool_calls:\n",
    "            formatted_calls.append(\n",
    "                f\"Tool Call ID: {call['id']}, Function: {call['name']}, Arguments: {call['args']}\"\n",
    "            )\n",
    "        return \"\\n\".join(formatted_calls)\n",
    "    return \"No tool calls\"\n",
    "\n",
    "async for event in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input={\"messages\": [input_message]},\n",
    "    stream_mode=\"messages\",):\n",
    "    \n",
    "    # Handle metadata events\n",
    "    if event.event == \"metadata\":\n",
    "        print(f\"Metadata: Run ID - {event.data['run_id']}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Handle partial message events\n",
    "    elif event.event == \"messages/partial\":\n",
    "        for data_item in event.data:\n",
    "            # Process user messages\n",
    "            if \"role\" in data_item and data_item[\"role\"] == \"user\":\n",
    "                print(f\"Human: {data_item['content']}\")\n",
    "            else:\n",
    "                # Extract relevant data from the event\n",
    "                tool_calls = data_item.get(\"tool_calls\", [])\n",
    "                invalid_tool_calls = data_item.get(\"invalid_tool_calls\", [])\n",
    "                content = data_item.get(\"content\", \"\")\n",
    "                response_metadata = data_item.get(\"response_metadata\", {})\n",
    "\n",
    "                if content:\n",
    "                    print(f\"AI: {content}\")\n",
    "\n",
    "                if tool_calls:\n",
    "                    print(\"Tool Calls:\")\n",
    "                    print(format_tool_calls(tool_calls))\n",
    "\n",
    "                if invalid_tool_calls:\n",
    "                    print(\"Invalid Tool Calls:\")\n",
    "                    print(format_tool_calls(invalid_tool_calls))\n",
    "\n",
    "                if response_metadata:\n",
    "                    finish_reason = response_metadata.get(\"finish_reason\", \"N/A\")\n",
    "                    print(f\"Response Metadata: Finish Reason - {finish_reason}\")\n",
    "                    \n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd139dcb",
   "metadata": {},
   "source": [
    "# Breakpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cacbf2",
   "metadata": {},
   "source": [
    "Goals\n",
    "\n",
    "`Human-in-the-loop`:\n",
    "\n",
    "(1) `Approval` - We can interrupt our agent, surface state to a user, and allow the user to accept an action\n",
    "\n",
    "(2) `Debugging` - We can rewind the graph to reproduce or avoid issues\n",
    "\n",
    "(3) `Editing` - You can modify the state \n",
    "\n",
    "LangGraph offers several ways to get or update agent state to support various `human-in-the-loop` workflows.\n",
    "\n",
    "[Breakpoints](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/breakpoints/#simple-usage), which provide a simple way to stop the graph at specific steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19427570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def multiply(a: int, b:int)-> int:\n",
    "    \"\"\" \n",
    "    Mulitply a and b\n",
    "    \n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int    \n",
    "    \"\"\"\n",
    "\n",
    "    return a * b\n",
    "\n",
    "def add(a:int, b:int)-> int:\n",
    "    \"\"\"\n",
    "    Add a and b\n",
    "\n",
    "    Agrs:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "\n",
    "    return a + b\n",
    "\n",
    "def div(a: int, b:int)-> float:\n",
    "    \"\"\"\n",
    "    Divide a by b\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "\n",
    "    return a/b\n",
    "\n",
    "tools = [multiply, add, div]\n",
    "llm = ChatOpenAI(model='gpt-4.1-nano')\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148ad433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState, START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "sys_mrg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
    "\n",
    "def assistant(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke([sys_mrg] + state[\"messages\"])]}\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\"assistant\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(interrupt_before=[\"tools\"], checkpointer=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e5ee9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_GFrcCO9zERxCigb3E9y4oJDk)\n",
      " Call ID: call_GFrcCO9zERxCigb3E9y4oJDk\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n"
     ]
    }
   ],
   "source": [
    "initial_input = {\"messages\": HumanMessage(content=\"Multiply 2 and 3\")}\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e80faf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tools',)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = graph.get_state(thread)\n",
    "state.next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3326ed27",
   "metadata": {},
   "source": [
    "Now, we'll introduce a nice trick.\n",
    "\n",
    "When we invoke the graph with `None`, it will just continue from the last state checkpoint!\n",
    "\n",
    "![breakpoints.jpg](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbae7985b747dfed67775d_breakpoints1.png)\n",
    "\n",
    "For clarity, LangGraph will re-emit the current state, which contains the `AIMessage` with tool call.\n",
    "\n",
    "And then it will proceed to execute the following steps in the graph, which start with the tool node.\n",
    "\n",
    "We see that the tool node is run with this tool call, and it's passed back to the chat model for our final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2eeb2a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_GFrcCO9zERxCigb3E9y4oJDk)\n",
      " Call ID: call_GFrcCO9zERxCigb3E9y4oJDk\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "6\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 2 and 3 is 6.\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97e9ed74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_YbSOMYlONBL4SZeGxfOR3VYo)\n",
      " Call ID: call_YbSOMYlONBL4SZeGxfOR3VYo\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_YbSOMYlONBL4SZeGxfOR3VYo)\n",
      " Call ID: call_YbSOMYlONBL4SZeGxfOR3VYo\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "6\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The product of 2 and 3 is 6.\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "initial_input = {\"messages\": HumanMessage(content=\"Multiply 2 and 3\")}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()\n",
    "\n",
    "# Get user feedback\n",
    "user_approval = input(\"Do you want to call the tool? (yes/no): \")\n",
    "\n",
    "# Check approval\n",
    "if user_approval.lower() == \"yes\":\n",
    "    \n",
    "    # If approved, continue the graph execution\n",
    "    for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "        event['messages'][-1].pretty_print()\n",
    "        \n",
    "else:\n",
    "    print(\"Operation cancelled by user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f30f981",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-academy-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
